{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "f2c5fa59",
   "metadata": {},
   "source": [
    "# This notebook perform fault slip analysis (FSA) based on principal stresses from CMG geomechanical simulations."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f95a5b57",
   "metadata": {},
   "source": [
    "# 1. Extract grid coordinates and fault id from Petrel exported files. Only need to do once for a 3D grid in Petrel. Save it as numpy array for later use."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c0d35684",
   "metadata": {},
   "source": [
    "# 2. Extract principla stresses (STRESMXP, STRESMNP, STRESINT) from CMG simulation results (gmch.sr3 -> rwo -> numpy)."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3cb8b910",
   "metadata": {},
   "source": [
    "# 3. Peform fault slip analysis"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "40a35453",
   "metadata": {},
   "source": [
    "## perform fault slip analysis on each case"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "0f2efa6f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processing case1...\n",
      "Processing case2...\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from fault_slip_analysis import FSA_stress_based\n",
    "\n",
    "n_cases = 2\n",
    "n_faults = 12\n",
    "fault_info = pd.read_csv('data/raw/fault_strike_dip.csv')\n",
    "coor_fault = np.load('data/coor_fault/JD_Sula_2025_gmc_coor&fault_reservoir.npy')\n",
    "FSA_by_fault = np.full((107,117,5,6), np.nan)\n",
    "for i in range(n_cases):\n",
    "    print(f\"Processing case{i+1}...\")\n",
    "    for j in range(n_faults):\n",
    "        row = fault_info.loc[fault_info['fault_id'] == j].iloc[0]\n",
    "        fault_slip = FSA_stress_based(\n",
    "            stress_folder_path = \"data/250819_stresses\",\n",
    "            parameter_file_path = \"data/params_responses/250819_CMG_parameters.csv\",\n",
    "            fault_cell_file_path = 'data/coor_fault/JD_Sula_2025_gmc_coor&fault_reservoir.npy',\n",
    "            # save_folder_path = \"data/250819_FSA_stress\",\n",
    "            case_name = f\"case{i+1}\", \n",
    "            fault_id = j,\n",
    "            fault_strike = row['fault_strike_deg'],\n",
    "            fault_dip = row['dip_angle_deg']\n",
    "            )\n",
    "\n",
    "        # save analysis to the specific fault \n",
    "        fault_id_mask = (coor_fault[:,:,:,3] == j)\n",
    "        FSA_by_fault[fault_id_mask] = fault_slip[fault_id_mask]\n",
    "\n",
    "    # save results for one case\n",
    "    np.save(f'data/250819_FSA/case{i+1}_FSA.npy', FSA_by_fault)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5571778f",
   "metadata": {},
   "source": [
    "## combine all cases in a numpy array (n_cases,n_faults,n_times)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "996e49dc",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processing case1...\n",
      "Processing case2...\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "from pathlib import Path\n",
    "\n",
    "base_path = Path('.')\n",
    "FSA_folder = base_path/'data'/'250819_FSA'\n",
    "save_file_prefix = '250915'\n",
    "\n",
    "n_cases = 2; n_faults = 12; n_times = 6\n",
    "fault_info = pd.read_csv('data/raw/fault_strike_dip.csv')\n",
    "coor_fault = np.load('data/coor_fault/JD_Sula_2025_gmc_coor&fault_reservoir.npy')\n",
    "FSA_combined = np.full((n_cases,n_faults,n_times), np.nan)\n",
    "for case_num in range(1,n_cases+1):\n",
    "    print(f\"Processing case{case_num}...\")\n",
    "    FSA = np.load(FSA_folder/f'case{case_num}_FSA.npy')\n",
    "\n",
    "    for fault_id in range(0,n_faults):\n",
    "        # save analysis to the specific fault \n",
    "        fault_id_mask = (coor_fault[:,:,:,3] == fault_id)\n",
    "        FSA_combined[case_num-1,fault_id,:] = np.nansum(FSA[fault_id_mask],axis=0)\n",
    "\n",
    "# save as csv\n",
    "np.save(base_path/'data'/f'{save_file_prefix}_FSA_combined.npy',FSA_combined)\n",
    "\n",
    "# np.savetxt(base_path/'data'/f'{save_file_prefix}_FSA_combined.csv',FSA_combined,delimiter=\",\",fmt=\"%.4f\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "e268853b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(2, 12, 6)\n",
      "[[  0.   0.   0.   0.   0.   0.]\n",
      " [  0.   0.   0.   0.   0.   0.]\n",
      " [  0.   0.   0.   0.   0.   0.]\n",
      " [  0.   0.   0.   0.   0.   0.]\n",
      " [  0. 394. 394. 394. 394. 394.]\n",
      " [  0.   0.   0.   0.   0.   0.]\n",
      " [ 60. 335. 335. 335. 335. 335.]\n",
      " [  0.   0.   0.   0.   0.   0.]\n",
      " [  0.   0.   0.   0.   0.   0.]\n",
      " [  0.   0.   0.   0.   0.   0.]\n",
      " [  0.   0.   0.   0.   0.   0.]\n",
      " [  0.   0.   0.   0.   0.   0.]]\n"
     ]
    }
   ],
   "source": [
    "print(FSA_combined.shape)\n",
    "print(FSA_combined[0,:,:])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2f391173",
   "metadata": {},
   "source": [
    "## calculate the (number of cases with fault slip / total cases)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "4c4e356e",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from pathlib import Path\n",
    "\n",
    "save_file_prefix = '250915'\n",
    "base_path = Path('.')\n",
    "\n",
    "FSA_combined = np.load(base_path/'data'/f'{save_file_prefix}_FSA_combined.npy')\n",
    "no_slip_count = np.sum(FSA_combined == 0, axis=0)\n",
    "slip_probability = 1 - no_slip_count/FSA_combined.shape[0]\n",
    "# np.savetxt(base_path/'data'/f'{save_file_prefix}_FSA_probability.csv',slip_probability,delimiter=\",\",fmt=\"%.4f\")\n",
    "# Save as CSV\n",
    "df = pd.DataFrame(\n",
    "    slip_probability,\n",
    "    columns=[f\"time_{t+1}\" for t in range(n_times)]\n",
    ")\n",
    "df.insert(0, \"fault_id\", range(n_faults))\n",
    "\n",
    "df.to_csv(base_path/'data'/f'{save_file_prefix}_FSA_probability.csv', index=False, float_format=\"%.4f\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
